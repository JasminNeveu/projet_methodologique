
\documentclass[a4paper,11pt]{article}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{lipsum}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{float}
\usepackage[colorlinks=true,
            linkcolor=black,
            citecolor=blue,
            urlcolor=blue]{hyperref}
\usepackage{caption}
\usepackage{etoolbox}
\usepackage{dsfont} %for \mathds
\pretocmd{\section}{\clearpage}{}{}
\captionsetup[figure]{justification=centering}
\usepackage{subcaption}
\theoremstyle{plain}

\usepackage{changes}
\newcommand{\Javier}[1]{\textcolor{purple}{#1}}

\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\norm}[1]{||#1||}

\newcommand{\1}{\mathbf{1}}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{cor}[theorem]{Corollary}
\newtheorem{assumption}{Assumption}[section]


\newtheorem{proposition}{Proposition}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}

\title{Mmethodological project report}
\author{Jasmin Neveu}
\date{\today}

\begin{document}



\begin{titlepage}
    \centering

    {\Large ENSAI \par}
    \vspace{2cm}
    {\large ATPA Track \par}
    {\large Academic Year 2024--2025 \par}
    \vspace{2cm}
    {\Huge\bfseries Methodological Project Report \par}
    \vspace{0.4cm}
    {\LARGE\itshape Selective Inference for Hierarchical Clustering \par}
    \vspace{2cm}
    \begin{flushleft}
        \textbf{Student:} Jasmin Neveu \\
        \vspace{0.2cm}
        \textbf{Supervisor:} Javier González-Delgado
    \end{flushleft}
    \vspace{1cm}
    \begin{flushleft}
        \textbf{Analyzed article:} \\
        Lucy L. Gao, Jacob Bien, and Daniela Witten, \\
        \textit{Selective Inference for Hierarchical Clustering}, \\
        Journal of the American Statistical Association,\\ 119(545), 332–342, 2024.\\
    \end{flushleft}
    \vspace{1cm}
    {\large Submission date: \today \par}
\end{titlepage}


\tableofcontents
\newpage

\section{Introduction}

Introduction text...

\section{Classical versus selective testing}\label{sec:testing}

\subsection{Hypothesis testing and \textit{p-values}}
Let $(\Omega, \mathcal{F},\mathbb{P})$ be a probability space, $(E,\mathcal{E})$ a topological space and $\mathcal{T}$ the $\sigma$-algebra generated by $\mathcal{E}$. A \textit{random variable} is a measurable function $X:(\Omega,\mathcal{F})\rightarrow(E,\mathcal{T})$. The \textit{(probability) distribution} of $X$ is the mapping $P:\mathcal{T}\rightarrow[0,1]$ such that  $P(O) = (\mathbb{P}\circ X^{-1})(O)$ for all $O\in\mathcal{T}$. We say that $P$ is \textit{supported} on $E$ and denote by $\mathcal{M}_1(E)$ the set of all probability distributions supported on $\mathcal{E}$. From now on, we will set $E=\mathbb{R}$ and simply write $\mathcal{M}(\mathbb{R})=\mathcal{M}$.

\begin{definition}[Hypothesis, Definition 1.1 in~\cite{Ramdas}]\label{def_dominate_sto}
  A \textit{hypothesis} $\mathcal{H}_0$ is a set of probability distributions in $\mathcal{M}$.
  A hypothesis is \textit{simple} if it is a singleton, such as $\lbrace P \rbrace$ or $\lbrace Q \rbrace$, and \textit{composite} otherwise. The complementary set $\mathcal{M} \setminus \mathcal{H}_0$ is called the \textit{alternative hypothesis} of $\mathcal{H}_0$.
\end{definition}

\begin{definition}[Test]\label{def_test}
  A \textit{test} for $\mathcal{H}_0$ is a binary partition of the sample space, defined by a mapping:
 \begin{equation}
  \begin{array}{rcl}
    \pi_{\mathcal{H}_0} : \Omega &\to& \{0,1\} \\
    \omega &\mapsto& \pi_{\mathcal{H}_0}(\omega).
  \end{array}
 \end{equation}
 For $\omega \in \Omega$, we say that the test \textit{rejects}
  $\mathcal H_0$ based on $\omega$ if $\pi_{\mathcal{H}_0}(\omega)=1$, and \textit{does not reject}
  $\mathcal H_0$ based on $\omega$ if $\pi_{\mathcal{H}_0}(\omega)=0$.
\end{definition}

In what follows, we will adopt the more standard notation:
\begin{equation*}
\mathbb{P}\left(\text{Reject } \mathcal{H}_0\right) = \mathbb{P}\left(\lbrace \omega \in \Omega\,:\,\pi_{\mathcal{H}_0}(\omega)=1\rbrace\right),
\end{equation*}
making the dependence on $\pi$ implicit.

\begin{definition}[Type I error]\label{def_type_error}
  We say that a test controls the type I error at level $\alpha$ if
 \begin{equation*}
    \mathbb{P}(\emph{Reject }\mathcal{H}_0) \leq \alpha, \quad \text{for }\alpha \in (0,1).
  \end{equation*}
  We say that it controls  the type I error exactly at level $\alpha$ if
  \begin{equation*}
    \mathbb{P}(\emph{Reject }\mathcal{H}_0) = \alpha, \quad\text{for } \alpha \in (0,1).
  \end{equation*}
\end{definition}

\begin{definition}[Stochastic dominance]\label{def_sto_def}
  Let $X$ and $Y$ be real-valued random variables.
  We say that $Y$ stochastically dominates $X$, and write
  \begin{equation*}
    X \preceq_{\mathrm{st}} Y,
  \end{equation*}
  if
  \begin{equation}
    \mathbb{P}(X \leq u) \geq \mathbb{P}(Y \leq u), \quad \forall\, u \in \mathbb{R}.
  \end{equation}
\end{definition}

\begin{definition}[Super-uniform random variable]\label{def_super_unif}
  Let $X$ be a real-valued random variable. We say that $X$ is super-uniform on [0,1], and write
  $X \sim \mathcal{SU}(0,1)$, if $X$ stochastically dominates a uniform random
  variable on $[0,1]$, that is, if
  \begin{equation}
    \mathbb{P}(X \leq u) \leq u, \quad \forall\, u \in [0,1].
  \end{equation}
\end{definition}

\begin{proposition}\label{prop_repartition}
  Let $X$ and $Y$ be real-valued random variables, with cumulative distribution functions $F_X$ and $F_Y$, respectively.
  If $X \preceq_{\mathrm{st}} Y$, then $F_X(Y) \sim \mathcal{SU}(0,1)$.
\end{proposition}


\begin{remark}\label{remark_FXX_unif}
If \(X=Y\), then \(F_X(X)\) is super-uniform on \([0,1]\).  
Moreover, if \(X\) has a continuous distribution function \(F_X\), then
\begin{equation}
F_X(X) \sim \mathcal{U}(0,1).
\end{equation}
\end{remark}

\begin{definition}[$p$-value, Definition 1.1 in~\cite{Ramdas}]\label{def_pvalue}
  Let $\mathcal{H}_0$ be a hypothesis. A $p$-value for $\mathcal{H}_0$ is a super-uniform random variable under $\mathcal{H}_0$. 
\end{definition}

We often build tests using $p$-values as $\pi = \mathds{1}\{p \leq \alpha \}$.

\begin{proposition}\label{prop_rejection_rule}
  Let $\mathcal{H}_0$ be a hypothesis and $p$ a $p$-value for $\mathcal{H}_0$. Then, the test $\pi = \mathds{1}{\{p \leq \alpha\}}$ controls the type I error at level $\alpha$, for $\alpha\in(0,1)$. 
\end{proposition}

\begin{definition}[Test statistic]
  A test statistic is a measurable function $T : \Omega \to \mathbb{R}$.
\end{definition}


From now on, we will consider the case of unilateral tests.
In this setting, to define a test based on the information given by a real-valued random variable $X$, $p$-values are often built in the form: 
\begin{equation}\label{unilateral_uniform_pvalue}
  p(x) = \mathbb{P}_{H_0}(T(X) \geq T(x))
\end{equation}
where $T$ is a test statistic and $x$ a realization of $X$.

The $p$-value \eqref{unilateral_uniform_pvalue} follows a uniform distribution under $\mathcal{H}_0$. However, we have defined $p$-values as being super-uniform random variables under the null hypothesis, which corresponds to a more general family of distributions. To adapt the classical form \eqref{unilateral_uniform_pvalue} to that setting, we introduce the following proposition.

\begin{proposition}\label{prop_test_stat_pvalue}
Let \(T\) and \(T'\) be two test statistics. Let \(X\) be a random variable and \(x\) a realization of \(X\).
Define
\begin{equation}
p(x) = \mathbb{P}_{\mathcal{H}_0}\!\bigl(T'(X) \ge T(x)\bigr).
\end{equation}
If
\begin{equation}
T'(X) \preceq_{\mathrm{st}} T(X)
\quad \text{under } \mathcal{H}_0,
\end{equation}
then \(p\) is a $p$-value for \(\mathcal{H}_0\).
\end{proposition}
\begin{remark}\label{remark_equal_statistics}
If \(T' = T\) and the cumulative distribution function \(F_T\) of \(T(X)\) is continuous
under \(\mathcal{H}_0\), then
\[
p \;\overset{\mathcal{H}_0}{\sim}\; \mathcal{U}(0,1).
\]
\end{remark}


In the classical setting, the null hypothesis is independent of the data. However, in many practical applications  $\mathcal{H}_0$ is chosen \textit{after seeing the data}. In this framework, the classical testing approaches built for type I error control are unsuitable. Instead, statistical guarantees need to be provided via \textit{selective inference}. In particular, the theory of statistical testing of data-driven null hypotheses is known as \textit{selective testing}~\cite{fithian}. The next section provides some examples that motivate this framework. 

\subsection{Examples motivating selective testing}

\subsubsection{Lasso}

To determine whether an explanatory variable helps explain a response variable through a linear regression model, a common practice is to test whether its associated coefficient is significantly different from zero.
In the context of classical linear regression, this falls within the framework of non-selective inference, because all coeficients are fixed \textit{a priori}. In contrast, Lasso regression uses an \(\ell_1\)-penalty to perform variable selection  \cite{10.1111/j.2517-6161.1996.tb02080.x}.
As only the coefficients selected by the Lasso can be tested, the null hypothesis depends on the outcome of the Lasso regression, and is therefore data-driven. This corresponds to a setting of selective inference, where the classical control of type I error fails. 

To illustrate the unsuitability of non-selective inference, consider a centered Gaussian vector $X=(X_1,\ldots,X_8)$ and set the model
\[
Y = X \beta +  \varepsilon, \quad \varepsilon \sim \mathcal{N}(0,1), \quad \beta = (3,1.5,0,0,2,0,0,0)^\top.
\]
We generated $n=100$ independent realizations of $(X,Y)$ and implemented the Lasso algorithm, obtaining the regularization path presented in Figure~\ref{fig:lasso_path}(a).
Then, we tested whether a randomly chosen coefficient selected by Lasso regression and among the trully null coefficients, equals 0.
After repeating this pipeline $M=2000$ times, we obtained the empirical $p$-value distribution depicted in Figure \ref{fig:lasso_path}(b).
We clearly see that the $p$-values are not super-uniform, motivating the use of a selective testing approach instead of naive testing after selection. 

\begin{figure}[H]
  \centering
  \begin{subfigure}{0.47\textwidth}
  \includegraphics[width = \textwidth]{images/lasso_path.png} 
	\caption{}
 \end{subfigure}
 	 \begin{subfigure}{0.47\textwidth}
 	 \includegraphics[width = \textwidth]{images/lasso_pvalues.png}
  \caption{}
  \end{subfigure}
  \caption{(a) Regularization path of the coefficients obtained using the Lasso algorithm with a single realization of $(X,Y)$. Some coefficients are zero, and three converge toward the theoretical values 
(3,1.5,2). (b) Empirical cumulative distribution function (ECDF) of the $p$-values obtained from tesing wheter a randomly chosen coefficient is null after selecting the coefficient by a Lasso regression. The ECDF was computed from $M$ = 2000 simulations.}
  \label{fig:lasso_path}
\end{figure}


%\begin{figure}[H]
%  \centering
%  \includegraphics[width = 0.7\textwidth]{images/pvalues_lasso.png}
%  \caption{Cumulative distribution function of the $p$-values obtained from significance tests
%of the third coefficient estimated by a Lasso regression. The empirical distribution function
%was computed using $M$ = 2000 simulations.}
%  \label{fig:pvalue_lasso}
%\end{figure}


\subsubsection{Publication bias}


In many areas of research, scientists tend to test for signficance only when the associated effect is found to be substantial. In other words, testing is performed after a selection process that filters out small effects. In that setting, controlling type I error at a fixed level $\alpha$ yields inflated false positive rates when considering the ensemble of all published studies. 
If $Y_i \sim \mathcal{N}(\mu_i,1)$ represents the effect size in a scientific study, whose significance is tested only if  $|Y_i| > 1$, a naive level $\alpha$ test $H_{0,i}: \mu_i = 0$ is invalid. Indeed, Fithian \cite{fithian} demonstrates that the false positive rate among true nulls reaches approximately 0.16, far exceeding the nominal 0.05 level. Valid inference requires thresholding $|Y_i|$ at 2.41 rather than 1.96, the $0.95$ quantile of the standard normal, imposing a more stringent criterion.


\subsubsection{Clustering}

Another remarkable example of selective inference appears when evaluating the performance of clustering algorithms by testing for the equality of cluster means.
To illustrate the need of using appropriate tests in the context of selective inference, we simulated $n = 100$ samples of a five-dimensional standard Gaussian random vector. Each sample was classified into $K = 3$ groups using hierarchical agglomerative clustering and $k$-means. Then, the equality of cluster means was tested using a classical t-test, for two randomly selected clusters. If the test controlled the type I error in this setting, the resulting $p$-value would be super-uniformly distributed under the null hypothesis. However, the `clustering + post-selection testing' procedure leads to a deviation from super-uniformity, as shown in Figure~\ref{fig:deux_images}.

\begin{figure}[H]
 
 \begin{subfigure}{0.47\textwidth}
  \centering
  \includegraphics[width=\textwidth]{images/hac_pvalues.png}%
  \caption{}
\end{subfigure}  
  \hfill
  \begin{subfigure}{0.47\textwidth}
  \includegraphics[width=\textwidth]{images/kmeans_pvalues.png}
	\caption{}  
  \end{subfigure}
  \caption{Empirical cumulative distribution functions of the $p$-values obtained after testing the equality of cluster means 
    for (a) hierarchical agglomerative clustering (HAC) and (b) $k$-means algorithms.
The distribution functions were computed using $M$ = 2000 simulations from a univariate centered normal distribution.
}
  \label{fig:deux_images}
\end{figure}


\subsection{Addressing selective testing}

Since the type I error is no longer controlled, alternative approaches are required.
Accordingly, we present three methods as described by Yoav Benjamini \cite{Benjamini}.

\subsubsection{Simultaneous Inference}

This approach controls the family-wise error rate across all hypotheses: 
\[
\mathbb{P}(\text{At least 1 false positive among all hypotheses}) \leq \alpha.
\]

This strategy proves highly conservative, ensuring that for every possible set of hypotheses, the probability of at least one false positive remains below $\alpha$.
\subsubsection{Sample splitting}

This approach consists in splitting the dataset into a training set $X$ and a test set $Y$.  
The training set $X$ is used to choose which hypotheses to test, denoted $H_0(X)$.  
Then, the tests are performed on the test set $Y$.

Although relatively simple to implement, this method raises several issues.  
First, statistical guarantees on the tests hold only if $X$ and $Y$ are independent, which is rarely the case in practice.  
In addition, comparing cluster means on the observations in $Y$ requires assigning each test point to one of the clusters obtained from the clustering performed on $X$, a step that compromises validity.
As discussed in \cite{Gao}, this strategy does not yield valid post-clustering inference in general.


\subsubsection{Conditional Inference}

This approach constitutes the most extensively studied framework for post-clustering inference.  
It controls the false positive rate conditional on hypothesis selection:  
\[
\mathbb{P}(\text{Reject } H_0(X) \mid H_0 \text{ selected}) \leq \alpha.
\]

In the remainder of the article, we employ this method to develop a statistical procedure for testing equality of cluster means following a clustering algorithm.

\Javier{Why new page?}

\section{Post-clustering inference}\label{sec:post_clustering_inf}

\Javier{As we are focusing on one article, I think it is better if we start right away with their approach. Here we can add a sentence saying that this article was the first to propose a feasible solution to post-clustering inference, and that we focus on the setting and approach introduced by the autorhs. Later in the discussion, we will mention its limitations and speak about other articles.}

\subsection{Gao \textit{et al.}'s approach}

\Javier{Use bold for matrix notation but not for matrix coefficients: $\mathbf{X}=(X_{ij})_{ij}$. For vectors in $\mathbb{R}^p$ don't use bold either, write $\bar{\mu}_G$ or $\bar{X}_G$, to be consistent with Gao \textit{et al.}'s notation.}

Let $\mathbf{X} \in \mathbb{R}^{n \times p}$ be the design matrix.
A cluster is an element of a partition of the samples.
We note $C$ a clustering algorithm and $C_1 \in C(\mathbf{X})$ a cluster obtained by the algorithm $C$ on $\mathbf{X}$.

We note $\bm{\mu} = (\bm{\mu}_{ij})_{ij}$ such as $\bm{\mu}_{ij} = \mathbb{E}[\mathbf{X}_{ij}]$, with $\mathbf{X}_{ij}$ the element in row i and column j of the matrix $\mathbf{X}$.
For a subset $G$ of $\{1,\ldots,n\}$, we note $\overline{\bm{\mu}}_G = \frac{1}{|G|} \displaystyle\sum_{i \in G} \mu_i \in \mathbb{R}^p$ and $\overline{\mathbf{X}}_G = \frac{1}{|G|} \displaystyle\sum_{i \in G} X_i \in \mathbb{R}^p$.

\Javier{Here, introduce the vector $\nu$ and the compact notation $\nu^T\mathbf{X}$, $\nu^T\boldsymbol{\mu}$.}

\begin{definition}[Null Hypothesis]
\begin{equation}\label{h0c1c2}\tag{H0}
H_0^{\{C_1,C_2\}}: \overline{\bm{\mu}}_{C_1} = \overline{\bm{\mu}}_{C_2}
\end{equation}
\end{definition}
\Javier{The previous equation is not really a definition. Say it rather in the text, also helping the reader understand the flow: `The goal is to test for the equality of cluster means, that is, testing the following null hypothesis:' and then add the equation (with a number).}

\Javier{Here, say that we are adopting the conditional inference framework described in the previous section which, in the setting of clustering, is equivalent to control the so-called selective type I error for clustering, defined below.}

\begin{definition}[\replaced{Selective type I}{Type I selective} error for clustering]
  We say that a test controls the \replaced{selective type I}{type I selective} error for clustering at leval $\alpha$ if
  \[
    \mathbb{P}_{H_0^{\{C_1,C_2\}}}(\textup{Reject} ~ H_0^{\{C_1,C_2\}} ~ | ~ C_1,C_2 \in C(\mathbf{X})) \leq \alpha,\quad \alpha \in (0,1).
  \]
  We say that it controls exactly the \replaced{selective type I}{type I selective} error for clustering at level $\alpha$ if
\[
  \mathbb{P}_{H_0^{\{C_1,C_2\}}}(\textup{Reject} ~ H_0^{\{C_1,C_2\}} ~ | ~ C_1,C_2 \in C(\mathbf{X})) = \alpha, \quad \alpha \in (0,1).
  \]

\end{definition}

%TODO: Gérer problème d'alinéa
\Javier{I think we should introduce the model here. The idea should be something like: To define a $p$-value that controls the selective type I error, model assumptions need to be imposed on $\mathbf{X}$. The authors in~\cite{Gao} adopt the following matrix normal model:}
\begin{equation}
\mathbf{X}\sim\mathcal{MN}_{n\times p}(\boldsymbol{\mu},\mathbb{I}_n,\sigma^2\mathbb{I}_p),
\end{equation}
\Javier{which means that the lines of $\mathbf{X}$ are independent $p$-dimensional random vectors distributed as $\mathcal{N}_p(\mu_i,\sigma^2\mathbb{I}_p)$, for every line $i\in\lbrace 1,\ldots,n\rbrace$. Note that this model imposes an indepedence assumption between the features (columns) of $\mathbf{X}$.
Then, we mention the $p$-value as you did below:}

To run a proper test, we need to control this error at level $\alpha$.
\replaced{Ideally}{In the ideal} \Javier{so french...}, we would like to define a p-value as \replaced{follows}{following}:
\[
  p_{ideal}(x) = \mathbb{P}_{H_0^{\{C_1,C_2\}}}(T(\mathbf{X}) \geq T(x) ~ | ~ C_1,C_2 \in C(\mathbf{X})),
\]
with $T$ being a test statistic.

\Javier{Now we mention the choice of $T$. Say that in~\cite{Gao} they set $T(\mathbf{X})=\norm{\nu^T\mathbf{X}}_2$ because we know its distribution under the null, which is $\mathcal{N}_p(\mathbf{0}_p,\norm{\nu}_2^2\sigma^2\mathbb{I}_p)$, explaining why. Then, continue:}

 However, $p_{ideal}$ cannot be evaluated in practice as it depends on parameters that are unknown~\cite{Gao}. \Javier{Whenever you make a statement that you don't really justify, cite the source.} \replaced{To}{Thus, to} address this issue, \replaced{the authors in~\cite{Gao} propose}{we need} to add technical events to the conditioning set\replaced{, considering the following quantity:}{ and consider:
$
  p(x) = \mathbb{P}_{H_0^{\{C_1,C_2\}}}(T(\mathbf{X}) \geq T(x) ~ | ~ C_1,C_2 \in C(\mathbf{X}), E[\mathbf{X}])
$}
\Javier{Here add the $p$-value defined by Gao, that is, Equation 8 in~\cite{Gao}.}
\added{as a $p$-value for~\eqref{h0c1c2}.}

\Javier{Now we haved defined the model, the hypothesis to test and the candidate $p$-value. The goal now is to prove that the candidate $p$-value $(i)$ can be computed under an analitically tractable form and $(ii)$ controls the selective type I error for clustering. Now, we say that to prove all that we first need a technical lemma that we state now (the Lemma about the independence that we proved). Add the lemma here and its proof to the appendix.} 

\appendix

\section{Proofs}

\subsection{Proofs of Section~\ref{sec:testing}}


\begin{proof}[Proof of Proposition~\ref{prop_repartition}]

Let \(G_X\) denote the generalized inverse (quantile function) of \(F_X\),
defined for \(u\in[0,1]\) as
\begin{equation}
G_X(u) = \inf\{x\in\mathbb{R} : F_X(x) \ge u\}.
\end{equation}

By definition of the generalized inverse,
\begin{equation}
\{F_X(Y) \le u\} = \{Y < G_X(u)\}.
\end{equation}
Therefore,
\begin{equation}
\mathbb{P}\bigl(F_X(Y)\le u\bigr)
= \mathbb{P}\bigl(Y < G_X(u)\bigr)
= F_Y\bigl(G_X(u)^-\bigr),
\end{equation}
where \(G_X(u)^-\) denotes the left limit at \(G_X(u)\).

Since \(X \preceq_{\mathrm{st}} Y\), we have \(F_Y \le F_X\) pointwise, and thus
\begin{equation}
F_Y\bigl(G_X(u)^-\bigr)
\le F_X\bigl(G_X(u)^-\bigr).
\end{equation}
By the defining property of the generalized inverse,
\begin{equation}
F_X\bigl(G_X(u)^-\bigr) \le u.
\end{equation}

Combining these inequalities yields
\begin{equation}
\mathbb{P}\bigl(F_X(Y)\le u\bigr) \le u,
\quad \forall\, u\in[0,1],
\end{equation}
which proves that \(F_X(Y)\) is super-uniform.


\end{proof}


\begin{proof}[Proof of Remark~\ref{remark_FXX_unif}]

  By the proposition \ref{prop_repartition}, we have that $F_X(X) \sim \mathcal{SU}(0,1)$. If \(F_X\) is continuous, then \(F_X(G_X(u)) = u\) for all \(u\in[0,1]\), and hence
  \begin{equation}
\mathbb{P}\bigl(F_X(X)\le u\bigr)
= F_X\bigl(G_X(u)\bigr)
= u,
\quad \forall\,u\in[0,1],
\end{equation}
which concludes the proof.

\end{proof}


\begin{proof}[Proof of Proposition~\ref{prop_rejection_rule}]

By definition of the rejection rule,
\begin{equation}
  \mathbb{P}_{\mathcal{H}_0}(\text{Reject} ~ \mathcal{H}_0)
= \mathbb{P}_{\mathcal{H}_0}(p \le \alpha).
\end{equation}
Since \(p\) is a $p$-value for \(\mathcal{H}_0\), it is super-uniform under
\(\mathcal{H}_0\), hence
\begin{equation}
\mathbb{P}_{\mathcal{H}_0}(p \le \alpha) \le \alpha.
\end{equation}
This establishes control of the type~I error at level \(\alpha\).
\end{proof}





\begin{proof}[Proof of Proposition~\ref{prop_test_stat_pvalue}]

Let \(F_{T'(X)}\) denote the distribution
function of \(T'(X)\) under $\mathcal{H}_0$.
By Proposition ~\ref{prop_repartition}, the stochastic dominance
\(T'(X) \preceq_{\mathrm{st}} T(X)\) implies that
\[
F_{T'(X)}\bigl(T(X)\bigr) \sim \mathcal{SU}(0,1).
\]

By definition,

\begin{equation}
p(x)
= \mathbb{P}_{\mathcal{H}_0}\!\bigl(T'(X) \ge T(x)\bigr)
= 1 - F_{T'(X)}\bigl(T(x)\bigr).
\end{equation}

Let \(u \in [0,1]\). Then
\begin{align}
\mathbb{P}_{\mathcal{H}_0}\bigl(p(X) \le u\bigr)
&= \mathbb{P}_{\mathcal{H}_0}\!\left(1 - F_{T'(X)}(T(X)) \le u\right) \\
&= \mathbb{P}_{\mathcal{H}_0}\!\left(F_{T'(X)}(T(X)) \ge 1-u\right) \\
&= 1 - \mathbb{P}_{\mathcal{H}_0}\!\left(F_{T'(X)}(T(X)) \le 1-u\right).
\end{align}

Since \(F_{T'(X)}(T(X))\) is super-uniform,
\begin{equation}
\mathbb{P}_{\mathcal{H}_0}\!\left(F_{T'(X)}(T(X)) \le 1-u\right) \le 1-u,
\end{equation}
and therefore
\begin{equation}
\mathbb{P}_{\mathcal{H}_0}\bigl(p(X) \le u\bigr) \le u.
\end{equation}

Thus\added{,} \(p\) is super-uniform under \(\mathcal{H}_0\), and hence a $p$-value.
\end{proof}


\begin{proof}[Proof of Remark~\ref{remark_equal_statistics}]

When \(T'=T\)
\begin{equation}
p(X) = \mathbb{P}_{\mathcal{H}_0}\bigl(T(X') \ge T(X)\bigr)
      = 1 - F_T\bigl(T(X)\bigr),
\end{equation}

By Remark ~\ref{remark_FXX_unif}, if \(F_T\) is continuous,
\begin{equation*}
F_T\bigl(T(X)\bigr) \sim \mathcal{U}(0,1).
\end{equation*}
Consequently, for any \(u\in[0,1]\),
\begin{align}
\mathbb{P}_{\mathcal{H}_0}\bigl(p(X) \le u\bigr)
&= \mathbb{P}_{\mathcal{H}_0}\bigl(1 - F_T(T(X)) \le u\bigr) \\
&= \mathbb{P}_{\mathcal{H}_0}\bigl(F_T(T(X)) \ge 1-u\bigr) \\
&= 1 - \mathbb{P}_{\mathcal{H}_0}\bigl(F_T(T(X)) \le 1-u\bigr) \\
&= 1 - (1-u) \\
&= u.
\end{align}
Thus \(p\) is uniformly distributed on \([0,1]\) under \(\mathcal{H}_0\).
\end{proof}


\subsection{Proofs of Section~\ref{sec:post_clustering_inf}}




\bibliographystyle{abbrv}
\bibliography{biblio.bib}

\end{document}
