
\documentclass[a4paper,11pt]{article}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{lipsum}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{float}
\usepackage[colorlinks=true,
            linkcolor=black,
            citecolor=blue,
            urlcolor=blue]{hyperref}
\usepackage{caption}
\usepackage{etoolbox}
\pretocmd{\section}{\clearpage}{}{}
\captionsetup[figure]{justification=centering}
\theoremstyle{plain}

\usepackage{changes}
\newcommand{\Javier}[1]{\textcolor{purple}{#1}}

\newtheorem{proposition}{Proposition}
\newcommand{\1}{\mathbf{1}}
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{cor}[theorem]{Corollary}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{remark}{Remark}[section]
\newtheorem{assumption}{Assumption}[section]

\title{Methodological project report}
\author{Jasmin Neveu}
\date{\today}

\begin{document}



\begin{titlepage}
    \centering

    {\Large ENSAI \par}
    \vspace{2cm}
    {\large ATPA Track \par}
    {\large Academic Year 2024--2025 \par}
    \vspace{2cm}
    {\Huge\bfseries Methodological Project Report \par}
    \vspace{0.4cm}
    {\LARGE\itshape Selective Inference for Hierarchical Clustering \par}
    \vspace{2cm}
    \begin{flushleft}
        \textbf{Student:} Jasmin Neveu \\
        \vspace{0.2cm}
        \textbf{Supervisor:} Javier González-Delgado
    \end{flushleft}
    \vspace{1cm}
    \begin{flushleft}
        \textbf{Analyzed article:} \\
        Lucy L. Gao, Jacob Bien, and Daniela Witten, \\
        \textit{Selective Inference for Hierarchical Clustering}, \\
        Journal of the American Statistical Association,\\ 119(545), 332–342, 2024.\\
    \end{flushleft}
    \vspace{1cm}
    {\large Submission date: \today \par}
\end{titlepage}


\tableofcontents
\newpage

\section{Introduction}

Introduction text...

\section{Classical versus selective testing}\label{sec:testing}

\subsection{Hypothesis testing and \textit{p-values}}

\Javier{\textbf{General comments}: This section is well-written and structured, but some work needs to be done. I have added some main comments about how to present some of the objects. We will discuss about that. Once this is done, we will speak about improving the flow by adding some text that helps the reader and creates a `story'.}

\Javier{As we have a 20 pages limit we will probably have to move the proofs to the appendix (which is the usual practice in research articles). I have added an appendix at the end where you can move the proofs. Then, we will mention in the text that proofs are provided in the Appendix.}

\Javier{Minor comment: to write equations, use \begin{equation}\label{my-equation}
2+2
\end{equation} so that equation numbers appear in the text and equations can be referenced therein, using ~\eqref{my-equation}. If you don't want an equation to be numbered, because it maybe not be very relevant, or it corresponds to calculations inside a proof, use 
\begin{equation*}
1+1.
\end{equation*}
Also, Definitions and Remarks are numbered like 2.1, 2.2 but Propositions like 1,2,3... The same numbering should be used for all.\\
}

Let $(\Omega,\mathcal{F})$ and $(E,\mathcal{E})$ be a measurable spaces.
We denote by $\mathcal{M}_1$ the set of all probability measures on $(\Omega,\mathcal{F})$.
A random variable with values in $E$ is a measurable function $X: (\Omega,\mathcal{F},\mathbb{P}) \rightarrow (E,\mathcal{E})$, with $\mathbb{P} \in \mathcal{M}_{1}$

\Javier{I think it is better is presented as follows (we will discuss next time about this). The main point is that I think is better to work directly on $E$ (the topological space where the random variable takes values) for clarity. We will clarify next time.}

Let $(\Omega, \mathcal{F},\mathbb{P})$ be a probability space, $(E,\mathcal{E})$ a topological space and $\mathcal{T}$ the $\sigma$-algebra generated by $\mathcal{E}$. A \textit{random variable} is a measurable function $X:(\Omega,\mathcal{F})\rightarrow(E,\mathcal{T})$. The \textit{(probability) distribution} of $X$ is the mapping $P:\mathcal{T}\rightarrow[0,1]$ such that  $P(O) = (\mathbb{P}\circ X^{-1})(O)$ for all $O\in\mathcal{T}$. We say that $P$ is \textit{supported} on $E$ and denote by $\mathcal{M}_1(E)$ the set of all probability distributions supported on $\mathcal{E}$. From now on, we will set $E=\mathbb{R}$ and simply write $\mathcal{M}_1(\mathbb{R})=\mathcal{M}_1$.

\Javier{Probably the previous paragraph should be formulated more in detail, especially when defining $\mathcal{M}_1$. To discuss.}

\begin{definition}[Hypothesis, \added{Definition} 1.1 in~\cite{Ramdas}]\label{def_dominate_sto}
  A \textit{hypothesis} is a set of probability \replaced{distributions}{measures} in $\mathcal{M}_1$.
  A hypothesis is \textit{simple} if it is a singleton, such as \replaced{$\lbrace P \rbrace$ or $\lbrace Q \rbrace$}{$\{\mathbb{P}\}$ or $\{\mathbb{Q}\}$}.
  Otherwise it is \textit{composite}.
\end{definition}

\begin{remark}
  We define the alternative hypothesis to $\mathcal{H}_0$ as $\mathcal{M}_1 \setminus \mathcal{H}_0$. \Javier{If you are defining something it must be inside a definition (not a remark). Add this sentence to the previous defintion.}
\end{remark}

\begin{definition}[Test]\label{def_test}
  A \textit{test} is a function defined as
  \[
  \begin{array}{rcl}
    \pi : \replaced{\Omega}{\mathcal{F}} &\to& \{0,1\} \\
    \replaced{\omega}{x} &\mapsto& \pi(\replaced{\omega}{x}).
  \end{array}
  \]
\end{definition}

\Javier{The test function is defined on $\Omega$ (it makes a decision based on an observation of the sample space, not based on a measurable set!). In the following definition you speak about rejection of $\mathcal{H}_0$ but this has not been defined. There has to be a link between the definition of test function (if defined and used) and the concept of rejecting/accepting a hypothesis. \textbf{Importantly}: You have defined a (simple) hypothesis as a distribution $\lbrace P \rbrace$. Then, what do we mean by \textit{rejecting} a hypothesis? This should be defined (no need to define a test function for that if you don't want to). We need to define rejection of $\mathcal{H}_0$ before speaking about type I error. If this is not clear we will discuss next time.}

\begin{definition}[Type I error]\label{def_type_error}
  We say that a test controls the type I error at level $\alpha$ if
  \[
    \mathbb{P}(\text{Reject }\mathcal{H}_0) \leq \alpha, \quad \text{for }\alpha \in (0,1).
  \]
  We say that it controls \deleted{exactly} the type I error \added{exactly }at level $\alpha$ if
  \[
    \mathbb{P}(\text{Reject }\mathcal{H}_0) = \alpha, \quad\text{for } \alpha \in (0,1).
  \]
\end{definition}

\Javier{Note: It is a good practice to write $\forall\,u$ instead of $\forall u$. I modified this in the following equations.}

\begin{definition}[Stochastic dominance]\label{def_sto_def}
  Let $X$ and $Y$ be real-valued random variables.
  We say that $Y$ stochastically dominates $X$, and write
  \[
    X \preceq_{\mathrm{st}} Y,
  \]
  if
  \[
    \mathbb{P}(X \leq u) \geq \mathbb{P}(Y \leq u), \quad \forall\, u \in \mathbb{R}.
  \]
\end{definition}

\Javier{Note: Use $\mathcal{SU}(0,1)$ instead of $SU(0,1)$. I have also replaced it.}

\begin{definition}[Super\added{-}uniform \added{random variable}]\label{def_super_unif}
  Let $X$ be a real-valued random variable. We say that $X$ is super\added{-}uniform, and write
  $X \sim \mathcal{SU}(0,1)$, if $X$ stochastically dominates a uniform random
  variable on $[0,1]$, that is, \added{if}
  \[
    \mathbb{P}(X \leq u) \leq u, \quad \forall\, u \in [0,1].
  \]
\end{definition}

\begin{proposition}\label{prop_repartition}
  Let $X$ and $Y$ be real-valued random variables, with \added{cumulative} distribution function\added{s} $F_X$ and $F_Y$\replaced{, respectively.}{.}
  If $X \preceq_{\mathrm{st}} Y$\added{,} then $F_X(Y) \sim SU(0,1)$.
\end{proposition}


\begin{proof}
Let \(G_X\) denote the generalized inverse (quantile function) of \(F_X\),
defined for \(u\in[0,1]\) \replaced{as}{by}
\[
G_X(u) = \inf\{x\in\mathbb{R} : F_X(x) \ge u\}.
\]

By definition of the generalized inverse,
\[
\{F_X(Y) \le u\} = \{Y < G_X(u)\}.
\]
Therefore,
\[
\mathbb{P}\bigl(F_X(Y)\le u\bigr)
= \mathbb{P}\bigl(Y < G_X(u)\bigr)
= F_Y\bigl(G_X(u)^-\bigr),
\]
where \(G_X(u)^-\) denotes the left limit at \(G_X(u)\).

Since \(X \preceq_{\mathrm{st}} Y\), we have \(F_Y \le F_X\) pointwise, and thus
\[
F_Y\bigl(G_X(u)^-\bigr)
\le F_X\bigl(G_X(u)^-\bigr).
\]
By the defining property of the generalized inverse,
\[
F_X\bigl(G_X(u)^-\bigr) \le u.
\]

Combining these inequalities yields
\[
\mathbb{P}\bigl(F_X(Y)\le u\bigr) \le u,
\quad \forall\, u\in[0,1],
\]
which proves that \(F_X(Y)\) is super-uniform.
\end{proof}


\begin{remark}\label{remark_FXX_unif}
If \(X=Y\), then \(F_X(X)\) is super-uniform on \([0,1]\).  
Moreover, if \(X\) has a continuous distribution function \(F_X\), then
\[
F_X(X) \sim \mathcal{U}(0,1).
\]
\end{remark}

\begin{proof}
By the proposition \ref{prop_repartition}, we have that $F_X(X) \sim SU(0,1)$. If \(F_X\) is continuous, then \(F_X(G_X(u)) = u\) for all \(u\in[0,1]\), and hence
\[
\mathbb{P}\bigl(F_X(X)\le u\bigr)
= F_X\bigl(G_X(u)\bigr)
= u,
\quad \forall\, u\in[0,1],
\]
\replaced{which concludes the proof.}{Therefore \(F_X(X)\sim \mathcal{U}(0,1)\) when \(X\) is continuously distributed.} \Javier{It's okay, but no need to repeat what we are proving at the end.}
\end{proof}

\Javier{Note: Write $p$-value instead of p-value.}

\begin{definition}[p-value, \added{Definition} 1.1 in~\cite{Ramdas}]\label{def_pvalue}
  Let $\mathcal{H}_0$ be a hypothesis. A p-value for $\mathcal{H}_0$ is a super-uniform random variable under $\mathcal{H}_0$. 
\end{definition}

\begin{proposition}
  Let \added{$\mathcal{H}:0$ be a hypothesis, $p$ a $p$-value for $\mathcal{H}_0$ and} $\mathcal{R}$ \deleted{be} the rejection rule defined by
  \[
    \mathcal{R} = \1_{\{p \leq \alpha\}}, \quad \alpha \in (0,1).
  \]
  \deleted{Let $p$ be a \textit{p-value} for $\mathcal{H}_0$.} Then\added{,} $\mathcal{R}$
  controls the type I error at level $\alpha$. 
\end{proposition}


\Javier{Here you use the term `rejection rule` (which is fine), that is closely related to `test` (defined above). This should be clarified: either use only test, either use only `rejection rule`, or (better) define `rejection rule` as a particular type of test based on the $p$-value thresholding. After defining $p$-value, you can say that $p$-values are often used to build a test by defining the partition of the sample space using the rejection rule $\mathbb{1}\lbrace p\leq \alpha$, for any $\alpha\in(0,1)$.}

\Javier{\textbf{Importantly}: in the previous proposition you say that the `rejection rule controls the type I error' but the type I error control has been defined in Def. 2.3 for a `test'. My previous comment should help clarify this.}

\begin{proof}
By definition of the rejection rule,
\[
  \mathbb{P}_{\mathcal{H}_0}(Reject ~ \mathcal{H}_0)
= \mathbb{P}_{\mathcal{H}_0}(p \le \alpha).
\]
Since \(p\) is a p-value for \(\mathcal{H}_0\), it is super-uniform under
\(\mathcal{H}_0\), hence
\[
\mathbb{P}_{\mathcal{H}_0}(p \le \alpha) \le \alpha.
\]
This establishes control of the type~I error at level \(\alpha\).
\end{proof}


\replaced{In this work/From now on,}{For the rest of the document}, we will \deleted{only} consider \added{the case of }unilateral test\added{s}. \replaced{In this setting}{Usually}, we define the \replaced{the $p$-value has the form}{\textit{p-value} by}:
\[
  p(X) = \mathbb{P}_{\mathcal{H}_0}(T(X) \geq t(x))
\]
\Javier{what is $T$?} \replaced{More}{But more} generally, we will define \textit{p-value} with the following proposition. \Javier{If it is a proposition it can't be a definition! The $p$-value has already been defined in Def. 2.6, so it can't be defined again. What we are doing here is \textit{characterizing} the $p$-value for a unilateral test in terms of a statistic $T$.}

\begin{proposition}\label{prop_test_stat_pvalue}
Let \(T\) and \(T'\) be two test statistics, i.e. transformations of $X$
\[
T : \mathcal{F} \to \mathbb{R},
\qquad
T' : \mathcal{F} \to \mathbb{R}.
\]
\Javier{If $T$ transforms $X$ it can't be taking values from $\mathcal{F}$!}
Let \(X\) be a random variable and \(x\) a realization of \(X\).
Define
\[
p(x) = \mathbb{P}_{\mathcal{H}_0}\!\bigl(T'(X) \ge T(x)\bigr).
\]
If
\[
T'(X) \preceq_{\mathrm{st}} T(X)
\quad \text{under } \mathcal{H}_0,
\]
then \(p\) is a p-value for \(\mathcal{H}_0\).
\end{proposition}

\begin{proof}
\deleted{Under \(\mathcal{H}_0\), let} \added{Let} \(F_{T'(X)}\) denote the distribution
function of \(T'(X)\) \added{under $\mathcal{H}_0$}.
By \replaced{Proposition}{proposition}~\ref{prop_repartition}, the stochastic dominance
\(T'(X) \preceq_{\mathrm{st}} T(X)\) implies that
\[
F_{T'(X)}\bigl(T(X)\bigr) \sim \mathrm{SU}(0,1).
\]

By definition,
\[
p(x)
= \mathbb{P}_{\mathcal{H}_0}\!\bigl(T'(X) \ge T(x)\bigr)
= 1 - F_{T'(X)}\bigl(T(x)\bigr).
\]

Let \(u \in [0,1]\). Then
\begin{align*}
\mathbb{P}_{\mathcal{H}_0}\bigl(p(X) \le u\bigr)
&= \mathbb{P}_{\mathcal{H}_0}\!\left(1 - F_{T'(X)}(T(X)) \le u\right) \\
&= \mathbb{P}_{\mathcal{H}_0}\!\left(F_{T'(X)}(T(X)) \ge 1-u\right) \\
&= 1 - \mathbb{P}_{\mathcal{H}_0}\!\left(F_{T'(X)}(T(X)) \le 1-u\right).
\end{align*}

Since \(F_{T'(X)}(T(X))\) is super-uniform,
\[
\mathbb{P}_{\mathcal{H}_0}\!\left(F_{T'(X)}(T(X)) \le 1-u\right) \le 1-u,
\]
and therefore
\[
\mathbb{P}_{\mathcal{H}_0}\bigl(p(X) \le u\bigr) \le u.
\]

Thus\added{,} \(p\) is super-uniform under \(\mathcal{H}_0\), and hence a $p$-value.
\end{proof}

\begin{remark}\label{remark_equal_statistics}
If \(T' = T\) and the distribution function \(F_T\) of \(T(X)\) is continuous
under \(\mathcal{H}_0\), then
\[
p \;\overset{\mathcal{H}_0}{\sim}\; \mathcal{U}(0,1).
\]
\end{remark}

\begin{proof}
When \(T'=T\)
\[
p(X) = \mathbb{P}_{\mathcal{H}_0}\bigl(T(X') \ge T(X)\bigr)
      = 1 - F_T\bigl(T(X)\bigr),
\]

By \replaced{Remark}{remark}~\ref{remark_FXX_unif}, if \(F_T\) is continuous,
\[
F_T\bigl(T(X)\bigr) \sim \mathcal{U}(0,1).
\]
Consequently, for any \(u\in[0,1]\),
\begin{align*}
\mathbb{P}_{\mathcal{H}_0}\bigl(p(X) \le u\bigr)
&= \mathbb{P}_{\mathcal{H}_0}\bigl(1 - F_T(T(X)) \le u\bigr) \\
&= \mathbb{P}_{\mathcal{H}_0}\bigl(F_T(T(X)) \ge 1-u\bigr) \\
&= 1 - \mathbb{P}_{\mathcal{H}_0}\bigl(F_T(T(X)) \le 1-u\bigr) \\
&= 1 - (1-u) \\
&= u.
\end{align*}
Thus \(p\) is uniformly distributed on \([0,1]\) under \(\mathcal{H}_0\).
\end{proof}

\Javier{Here we should have a paragraph introduce what selective testing is. Just saying that in the classical setting the null hypothesis is independent of the data but in several settings $\mathcal{H}_0$ is chosen after seeing the data, what makes the classical testing approaches unsuitable. This is called selective testing, and it is motivated with some examples in the next section. The reader needs to have an idea of what we mean by selective testing before starting reading the examples.}

\subsection{Examples motivating selective testing}

\subsubsection{Lasso}

To determine whether an explanatory variable helps explain a response variable through a linear regression model, \replaced{a common practice is to test}{one performs} \deleted{a significance test on the coefficient associated with that variable, testing} whether \added{it associated coefficient} \replaced{it} is significantly different from zero. In the context of classical linear regression, this falls within the framework of \replaced{non-selective}{standard} inference.

In contrast, Lasso regression uses an \(\ell_1\)-penalty to perform variable selection. Not all coefficients are tested—only those selected by the Lasso are considered. It is therefore impossible to define in advance which coefficients will be tested, since they depend on the outcome of the Lasso regression. \replaced{This corresponds to a setting of}{This creates a situation of} selective inference.

During the Algorithmic Programming course supervised by Brian Staber, we implemented a proximal gradient descent algorithm. We simulated a dataset as follows: let \(x_1, \dots, x_8\) be centered gaussian random variables with correlation matrix \((R_{ij})_{1\le i,j\le 8}\) defined by \Javier{Say instead: to illustrate the unsuitability of classical inference in this context, we simulate samples... peform a LASSO for each sample, etc. You can add in a footnote that this is based on the code by Brian Staber.}
\[
R_{ij} = 0.5^{|i-j|}, \quad 1\le i,j\le 8.
\]
The response is modeled as
\[
y = \beta^\top x + 3 \varepsilon, \quad \varepsilon \sim \mathcal{N}(0,1), \quad \beta = (3,1.5,0,0,2,0,0,0)^\top.
\]
We generated a sample of size \(n=100\) and obtained the following regularization path.

\begin{figure}[H]
  \centering
  \includegraphics[width = 0.7\textwidth]{images/lasso_path.png}
  \caption{Regularization path of the coefficients obtained using the Lasso algorithm.
Some coefficients are zero, and three converge toward the theoretical values 
(3,1.5,2).}
  \label{fig:lasso_path}
\end{figure}

\Javier{Some explanation is needed about the next figure. We tested $\beta_3=$ for each simulated sample and obtained the empirical $p$-value distribution depicted in Figure~\ref{fig:pvalue_lasso}. $p$-values are not super-uniform, therefore...}

\begin{figure}[H]
  \centering
  \includegraphics[width = 0.7\textwidth]{images/pvalues_lasso.png}
  \caption{Cumulative distribution function of the p-values obtained from significance tests
of the third coefficient estimated by a Lasso regression. The \added{empirical} distribution function
was computed using $M$ = 2000 simulations.}
  \label{fig:pvalue_lasso}
\end{figure}


\subsubsection{Publication bias}
\cite{fithian}
\Javier{Leave the clustering example at the end.}

\subsubsection{Clustering}

\Javier{I would start maybe like: Another remarkable example of selective inference appears when evaluating the performace of clustering algorithms by testing for the equality of cluster means (or something like that).}
To illustrate the \replaced{need}{importance} of using appropriate tests in the context of selective inference, I simulated samples of gaussian random variables \replaced{that were classified into $K=3$ groups using}{to which I applied clustering methods} (hierarchical clustering and \replaced{$k$-means}{\textit{k-means}}).

\Javier{Even if it is only you, avoid using `I` and use `we` or use passive tenses or forms like `we can simulate`, `this can be illustrated by simulating', etc.}

\added{For each sample, the }{I then performed tests of} equality of \added{cluster} means \added{was tested using a classical z-test, for two randomly selected clusters.}\deleted{(\textit{z-tests}) on clusters chosen in a data-dependent manner.}
If the test \deleted{of equality of means} \deleted{correctly} controlled the type I error in this setting, the resulting p-value would \replaced{be uniformly distributed under the null.}{follow a uniform distribution on ([0,1]) when the null hypothesis is true.}
\replaced{However,}{In practice, however}, the `clustering + post-selection testing' procedure leads to a deviation from the uniform distribution, demonstrating the lack of control of the type I error, \added{as shown in Figure~\ref{fig:deux_images}}.


\begin{figure}[H]
  \centering
  \includegraphics[width=0.45\textwidth]{images/cah_pvalues.png}%
  \hfill
  \includegraphics[width=0.45\textwidth]{images/kmeans_df.png}
  \caption{Cumulative distribution functions of the p-values obtained from tests of equality of means
    between clusters after hierarchical clustering (\textit{CAH}) and \textit{k-means} algorithms.
The distribution functions were computed using $M$ = 2000 simulations from a multivariate normal distribution with
  $\mu = 0_{n\times p}$ \Javier{I guess you mean $0_p$} et $\Sigma = 0.98^{|i-j|}$ pour $1 \leq i,j \leq n \times p$, \Javier{I don't understand the $n\times p$ here}. avec $n = 100$ et $p = 5$. \Javier{Mention that you set the clustering algorithms to choose $K=3$ clusters, and that you tested the equality of cluster means for two randomly selected clusters (if that's the case).}}
  \label{fig:deux_images}
\end{figure}

\Javier{Write $k$-means instead of \textit{k-means}, CAH instead of \textit{CAH} and $p$-value instead of p-value.}

\subsection{Addressing selective testing}

\section{Post clustering inference}

\appendix

\section{Proofs}

\subsection{Proofs of Section~\ref{sec:testing}}

Here use:

\begin{proof}[Proof of Proposition~\ref{prop_repartition}]

\end{proof}


\bibliographystyle{abbrv}
\bibliography{biblio.bib}

\end{document}
